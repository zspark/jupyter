{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1cdc5b8-f617-42ed-b2cf-0fefc1c07b29",
   "metadata": {},
   "source": [
    "# world size, scale, zoom\n",
    "\n",
    "in mapbox, `worldSize` is measured in `fake pixel` which means we just protend the number of size is in pixel, not real pixel size of screen. Every tile has a dimension of `512*512(pixels)`, so under such a predefined scenario, we have a world size of `512` under tile `level 0`. and `2048` under `level 2`.\n",
    "\n",
    "```python\n",
    "worldSize = math.pow(2, tileLevel) * 512;\n",
    "```\n",
    "\n",
    "but we dot calculate worldSize in such a way, instead, we use a independent variable called `scale` or `zoom` to do so.\n",
    "\n",
    "* `scale` is, as its name defined, used for scale base size of world `512`, if current world size is 2048 means scaled 4 times. (scale==4.0);\n",
    "* `zoom` is a continuous variable (a float not a integer) kind of like tile level which is a discrete variable (a integer)\n",
    "\n",
    "nomally, `scale` along with `zoom` has coherence under its logics, we define the world size, then we known its `scale` and `zoom`. OR we get `worldSize` and `scale` given by `zoom`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02158649-138a-485d-9861-696f36403926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "world scale: 1.36, world size: 696.32, world zoom: 0.44360665147561484\n",
      "world zoom: 0.7, world size: 831.7464538687851, world scale: 1.624504792712471\n"
     ]
    }
   ],
   "source": [
    "import math;\n",
    "scale = 1.36;\n",
    "worldSize = 512 * scale;\n",
    "zoom = math.log2(scale);\n",
    "print(f\"world scale: {scale}, world size: {worldSize}, world zoom: {zoom}\");\n",
    "\n",
    "zoom = 0.7;\n",
    "scale = math.pow(2, zoom);\n",
    "worldSize = 512 * scale;\n",
    "print(f\"world zoom: {zoom}, world size: {worldSize}, world scale: {scale}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f06c17-3ad5-4f39-9fc4-0ec1adf19a59",
   "metadata": {},
   "source": [
    "# spaces\n",
    "\n",
    "model to world and world to camera matrices are simple, they are just affine transformations, the last(bottom) row must be $[0,0,0,1]$\n",
    "\n",
    "$$M_{model-view} = \\begin{bmatrix}\n",
    "a&&b&&c&&T_x \\\\\n",
    "d&&e&&f&&T_y\\\\\n",
    "g&&h&&i&&T_z\\\\\n",
    "0&&0&&0&&1\n",
    "\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940df921-baba-4856-bde3-4ada2f1f5fb2",
   "metadata": {},
   "source": [
    "## perspective projection matrix and MVP\n",
    "\n",
    "the form of `perspective projection matrix` is deduced as the following formula. **but please be cautious the matrix is deduced under OpenGL CVV( canonical view volume) with z value ranged from -1 to +1;**\n",
    "\n",
    "NOTE: WebGPU/Vulkan/DirectX/Metal all have 0 to +1 in range."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad03d8f-4ee5-42bf-b45e-88f0e32baf27",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "$$\n",
    "M_{pers} =\n",
    "\\begin{bmatrix} \n",
    "\\frac {2near}{right-left}&0&\\frac{left+right}{right-left}&0\\\\\n",
    "0&\\frac {2near}{top-bottom}&-\\frac {bottom+top}{top-bottom}&0\\\\\n",
    "0&0&\\frac {-(near+far)}{far-near}&\\frac {-2near*far}{far-near}\\\\\n",
    "0&0&-1&0 \n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb61c8c-c2b0-47a8-b493-c9348f234d8a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "mapbox uses following code to gen such matrix:\n",
    "```js\n",
    "// mapbox perspective projection matrix version:\n",
    "function perspectiveNO(out, fovy, aspect, near, far) {\n",
    "    let f = 1 / Math.tan(fovy / 2), nf;\n",
    "    out[0] = f / aspect;    out[4] = 0; out[08] = 0;     out[12] = 0;\n",
    "    out[1] = 0;             out[5] = f; out[09] = 0;     out[13] = 0;\n",
    "    out[2] = 0;             out[6] = 0;\n",
    "    out[3] = 0;             out[7] = 0; out[11] = -1;    out[15] = 0;\n",
    "    if (far != null && far !== Infinity) {\n",
    "        nf = 1 / (near - far);\n",
    "        out[10] = (far + near) * nf;\n",
    "        out[14] = 2 * far * near * nf;\n",
    "    } else {\n",
    "        out[10] = - 1;\n",
    "        out[14] = - 2 * near;\n",
    "    }\n",
    "    return out;\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bc235a-c52c-4674-b7b2-ddf74fb56c9d",
   "metadata": {},
   "source": [
    "MVP matrix:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "M_{mvp} &= M_{pers} \\times M_{mode-view} \\\\ &=\n",
    "\\begin{bmatrix} \n",
    "\\frac {2near}{right-left}&0&\\frac{left+right}{right-left}&0\\\\\\ \n",
    "0&\\frac {2near}{top-bottom}&-\\frac {bottom+top}{top-bottom}&0\\\\\\ \n",
    "0&0&\\frac {-(near+far)}{far-near}&\\frac {-2near*far}{far-near}\\\\\\ \n",
    "0&0&-1&0 \n",
    "\\end{bmatrix} \\times\n",
    "\\begin{bmatrix}\n",
    "a&&b&&c&&T_x \\\\\n",
    "d&&e&&f&&T_y\\\\\n",
    "g&&h&&i&&T_z\\\\\n",
    "0&&0&&0&&1\n",
    "\\end{bmatrix} \\\\&=\n",
    "\\begin{bmatrix}\n",
    "-/-&&-/-&&-/-&&-/-\\\\\n",
    "-/-&&-/-&&-/-&&-/-\\\\\n",
    "-/-&&-/-&&-/-&&-/-\\\\\n",
    "-g&&-h&&-i&&-Tz\n",
    "\\end{bmatrix}\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "If we use such matrix to multiply a random vector $P_{0-model} = [x_0,y_0,z_0,w_0]$\n",
    "\n",
    "w value in clipping space would be: $w_1 = -gx_0-hy_0-iz_0-T_z$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05e6bcb-1e67-4b27-b1b1-6e248ad955fe",
   "metadata": {},
   "source": [
    "## NDC\n",
    "\n",
    "so after tranfomation, point $P_0$ now is :\n",
    "\n",
    "$$\n",
    "P_{0-clip} = \\begin{bmatrix}\n",
    "x_1 \\\\ y_1 \\\\ z_1 \\\\ w_1\n",
    "\\end{bmatrix};\n",
    "P_{0-ndc} = \\begin{bmatrix}\n",
    "x_1/w_1 \\\\ y_1/w_1 \\\\ z_1/w_1 \\\\ 1.0\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6d89a2-9f43-474f-acd7-19d6979acea1",
   "metadata": {},
   "source": [
    "## screen\n",
    "\n",
    "$$\n",
    "M_{screen} = \n",
    "\\begin{bmatrix}\n",
    "scale_x && 0.0 && 0.0 && trans_x\\\\\n",
    "0.0 && scale_y && 0.0 && trans_y \\\\\n",
    "0.0 && 0.0 && 1.0 && 0.0 \\\\\n",
    "0 && 0 && 0 && 1.0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "M_{screen} \\times P_{0-clip} = \n",
    "\\begin{bmatrix}\n",
    "scale_x x_1+w_1 trans_x \\\\\n",
    "scale_y y_1+w_1 trans_y \\\\\n",
    "z_1 \\\\\n",
    "w_1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "M_{screen} \\times P_{0-ndc} = \n",
    "\\begin{bmatrix}\n",
    "scale_x \\frac{x_1}{w_1}+ trans_x \\\\\n",
    "scale_y \\frac{y_1}{w_1}+ trans_y \\\\\n",
    "\\frac{z_1}{w_1} \\\\\n",
    "1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "as the results illustrated, we do `perspective division` right after clipping is the same as we do it in the vertex shader. \n",
    "\n",
    "in mapbox, class `Transform` defines projection matrix called `cameraToClip`, and `worldToCamera` as view matrix, they all recalculated in `_calcMatrices` member method, and mapbox multipled they two into a PV matrix called `projMatrix` which maybe used to get the final MVP matrix of a specific tile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a50fd79-30c7-4581-b7f8-828f8f065674",
   "metadata": {},
   "source": [
    "# labelPlaneMatrix\n",
    "\n",
    "In `Transform` class, there is a matrix called `labelPlaneMatrix`, if u check its doc, u may know this matrix is \"`Inverse of glCoordMatrix, from NDC to screen coordinates, [-1, 1] x [-1, 1] --> [0, w] x [h, 0]`\". Yes that's right, but same with `projMatrix` in `Transform` class too, it's just a half-way matrix, the final one should be multiplied by tile's `projMatrix`(a mat cascaded as `MVP` matrix).\n",
    "\n",
    "so, the final `labelPlaneMatrix` can transform a point in tile space directly to screen space, awesome!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac870493-2f36-4e53-ada3-73ff4bb48912",
   "metadata": {},
   "source": [
    "# SymbolBuffers::dynamicLayoutVertexArray (type of StructArray)\n",
    "\n",
    "Symbol Projection continueously update symbols' placement (layout), the newly calculated positions are all stored in this array with 4 float components as a record `a_projected_pos`, and then upload onto `dynamicLayoutVertexBuffer` which is a instance of `VertexBuffer`;\n",
    "\n",
    "what should be noticed is: `x`and`y` components in each record represents a coordinate of a position under screen space, and the last (fourth) component illustrates `segment_angle`, which you should take into consideration while programming shader codes. Third value is useless at the moment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12860147-569e-4e0f-9f53-171f5806aa85",
   "metadata": {},
   "source": [
    "```c\n",
    "//// pseudo code:\n",
    "attribute vec4 a_projected_pos;\n",
    "\n",
    "// offset from pivot pos, in pixels;\n",
    "attribute vec2 a_offset;\n",
    "\n",
    "// in radian\n",
    "highp float segment_angle = a_projected_pos[3]; \n",
    "highp float angle_sin = sin(segment_angle);\n",
    "highp float angle_cos = cos(segment_angle);\n",
    "mat2 rotation_matrix = mat2(angle_cos, -1.0 * angle_sin, angle_sin, angle_cos);\n",
    "vec2 offset = rotation_matrix * a_offset;\n",
    "\n",
    "// pivot position (screen space);\n",
    "vec4 projected_pos = vec4(a_projected_pos.xy, 0.0, 1.0);\n",
    "\n",
    "// `u_coord_matrix` can transform vector in screen space to NDC.\n",
    "gl_Position = u_coord_matrix * vec4(projected_pos.xy + offset, 0.0, 1.0);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae65fb70-2cd7-4ca7-8ee1-f5bdf66e108a",
   "metadata": {},
   "source": [
    "# all major matrixes in mapbox\n",
    "\n",
    "* **Transform::projMatrix**: projection from world coordinates (mercator scaled by worldSize) to clip coordinates. equals to `VP` matrix.\n",
    "* **Transform::glCoordMatrix**: Transform from screen coordinates to GL NDC, `[0,w] x [h,0] --> [-1,1] x [-1,1]`.\n",
    "* **Transform::labelPlaneMatrix**: Inverse of glCoordMatrix, from NDC to screen space, `[-1, 1] x [-1, 1] --> [0, w] x [h, 0]`.\n",
    "* temp **posMatrix**: transform from tile space to world space.\n",
    "* **OverscaledTileID::projMatrix**: equals to `Transform::projMatrix * posMatrix`, the final `MVP` matrix for a specific tile.\n",
    "* temp **labelPlaneMatrixRendering**: equal to `Transform.labelPlaneMatrix * OverscaledTileID::projMatrix`, the direct matrix transforms position (in tile space with 8192 in extent) to screen space. Please consider `perspective division` issuses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e8b452-c994-4419-b314-5b97757641af",
   "metadata": {},
   "source": [
    "# terrain\n",
    "\n",
    "mapbox supports at least two types of terrains: `mapbox` self-defined terrain, and `terrarium`. \n",
    "\n",
    "These terrains are all stored within images, to encode(pack) and decode(unpack) values from each other, different types have different formulas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a905d3f-c1fc-49dc-b17b-de6ee9103b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapbox encoding: 0 meter encodes to [1, 134, 160, 255]\n",
      "mapbox decode: [1, 134, 27, 255] decodes to -13.299999999999272\n"
     ]
    }
   ],
   "source": [
    "import math;\n",
    "\n",
    "# mapbox:\n",
    "def mapboxEncode(height):\n",
    "  value = math.floor((height + 10000) * 10);\n",
    "  r = value >> 16;\n",
    "  g = value >> 8 & 0x0000FF;\n",
    "  b = value & 0x0000FF;\n",
    "  return [r, g, b, 255];\n",
    "\n",
    "print(f\"mapbox encoding: 0 meter encodes to {mapboxEncode(0)}\")\n",
    "\n",
    "color=[1,134,27,255];\n",
    "def mapboxDecode(c):\n",
    "    return (c[0]*256*256+c[1]*256+c[2])*.1 - 10000.0;\n",
    "\n",
    "print(f\"mapbox decode: {color} decodes to {mapboxDecode(color)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0620e590-50a8-4eb7-b5ca-57066f099cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "terrarium encode: 0 meter encodes to [128, 0, 0]\n",
      "terrarium height: [1, 134, 160, 255] decodes to -32377.375\n"
     ]
    }
   ],
   "source": [
    "# terrarium:\n",
    "def terrariumEncode(height):\n",
    "  height += 32768;\n",
    "  r = math.floor(height / 256.0);\n",
    "  g = math.floor(height % 256);\n",
    "  b = math.floor((height - math.floor(height)) * 256.0);\n",
    "  return [r, g, b];\n",
    "\n",
    "print(f\"terrarium encode: 0 meter encodes to {terrariumEncode(0)}\");\n",
    "\n",
    "color=[1,134,160,255];\n",
    "def terrariumDecode(c):\n",
    "    # 32768 == 2 to 15 power\n",
    "    return (c[0]*256+c[1]+c[2]/256)-32768;  \n",
    "\n",
    "print(f\"terrarium height: {color} decodes to {terrariumDecode(color)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
